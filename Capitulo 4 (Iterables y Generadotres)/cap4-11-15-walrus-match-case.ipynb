{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterando en elementos en contenedores separados\n",
    "\n",
    "4.11\n",
    "\n",
    "- Problema\n",
    "         Necesita realizar la misma operaci√≥n en muchos objetos, pero los objetos est√°n contenidos en diferentes contenedores y le gustar√≠a evitar bucles anidados sin perder la legibilidad de su c√≥digo.\n",
    "\n",
    "\n",
    "- soluci√≥n\n",
    "         El m√©todo itertools.chain () se puede utilizar para simplificar esta tarea. Toma una lista de iterables como entrada y devuelve un iterador que enmascara de manera efectiva el hecho de que realmente est√°s actuando en varios contenedores.\n",
    "         \n",
    "Para ilustrarlo, considere este ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "x\n",
      "y\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = ['x', 'y', 'z']\n",
    "for x in chain(a, b):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un uso com√∫n de chain () es en programas en los que le gustar√≠a realizar ciertos\n",
    "operaciones en todos los elementos a la vez, pero los elementos se agrupan en diferentes\n",
    "conjuntos.   \n",
    "Por ejemplo:\n",
    "\n",
    "```python\n",
    "    # Various working sets of items\n",
    "    active_items = set()\n",
    "    inactive_items = set()\n",
    "    # Iterate over all items\n",
    "    for item in chain(active_items, inactive_items):\n",
    "        # Process item\n",
    "```\n",
    "\n",
    "Esta soluci√≥n es mucho m√°s elegante que usar dos bucles separados, como se muestra a continuaci√≥n:\n",
    "\n",
    "```python\n",
    "        for elemento in active_items:\n",
    "            # Elemento de proceso\n",
    "            ...\n",
    "\n",
    "        for elemento in inactive_items:\n",
    "            # Elemento de proceso\n",
    "            ...\n",
    "```\n",
    "\n",
    "itertools.chain () acepta uno o m√°s iterables como argumentos. Entonces funciona creando\n",
    "un iterador que consume y devuelve sucesivamente los elementos producidos por cada uno de\n",
    "los iterables suministrados que proporcion√≥. Es una distinci√≥n sutil, pero chain() es m√°s eficiente que primero combinar las secuencias e iterar.   \n",
    "Por ejemplo:\n",
    "\n",
    "```python\n",
    "        # Ineficiente\n",
    "        for x in a + b:\n",
    "            ...\n",
    "        # Mejor\n",
    "        for x in chain(a, b):\n",
    "            ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer caso, la operaci√≥n a + b crea una secuencia completamente nueva y, adem√°s\n",
    "requiere que a y b sean del mismo tipo. chain () no realiza tal operaci√≥n, por lo que est√° lejos m√°s eficiente con la memoria si las secuencias de entrada son grandes y se puede aplicar f√°cilmente cuando los iterables en cuesti√≥n son de diferentes tipos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear canalizaciones de procesamiento de datos\n",
    "\n",
    "4.12\n",
    "\n",
    "- Problema\n",
    "        Desea procesar datos de forma iterativa en el estilo de una canalizaci√≥n de procesamiento de datos (similar a Tuber√≠as Unix). Por ejemplo, tiene una gran cantidad de datos que deben procesarse, pero no cabe del todo en la memoria.\n",
    "\n",
    "\n",
    "- Soluci√≥n\n",
    "        Las funciones de generador son una buena forma de implementar canalizaciones de procesamiento.   \n",
    "\n",
    "Para ilustrar, suponga que tiene un directorio enorme de archivos de registro que desea procesar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import gzip\n",
    "import re\n",
    "import bz2\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = os.walk(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('d:\\\\recetas-python\\\\Capitulo 4 (Iterables y Generadotres)',\n",
       " [],\n",
       " ['arc.txt',\n",
       "  'cap4-1-7.ipynb',\n",
       "  'cap4-11-15-walrus-match-case.ipynb',\n",
       "  'cap4-8-10.ipynb',\n",
       "  'test'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_find(busqueda, top=os.getcwd()):\n",
    "    \"\"\"Encuentra archivos en un √°rbol de directorios que coinciden con un patr√≥n.\n",
    "    \n",
    "    Utiliza os.walk() para recorrer recursivamente un √°rbol de directorios y \n",
    "    fnmatch para aplicar filtros de patr√≥n tipo shell. Devuelve las rutas \n",
    "    completas de los archivos coincidentes.\n",
    "    \n",
    "    Args:\n",
    "        busqueda (str): Patr√≥n de b√∫squeda tipo shell (ej: '*.txt', 'cap4*.*')\n",
    "        top (str): Ruta del directorio ra√≠z donde comenzar la b√∫squeda \n",
    "                    (por defecto es el directorio actual)\n",
    "        \n",
    "    Yields:\n",
    "        str: Ruta completa de cada archivo que coincide con el patr√≥n\n",
    "        \n",
    "    Example:\n",
    "        >>> for archivo in gen_find('*.py', '/home/user'):\n",
    "        ...     print(archivo)\n",
    "        /home/user/script1.py\n",
    "        /home/user/subdir/script2.py\n",
    "    \"\"\"\n",
    "    for path, carpetas, archivos in os.walk(top):\n",
    "        for nombre in fnmatch.filter(archivos, busqueda):\n",
    "            yield os.path.join(path, nombre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object gen_find at 0x000001E517C4BA40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos = gen_find(\"cap4*.*\",os.getcwd())\n",
    "archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos=list(archivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_opener(filenames):\n",
    "    \"\"\"Abre una secuencia de archivos, detectando autom√°ticamente el formato.\n",
    "    \n",
    "    Lee nombres de archivo y abre cada uno, detectando autom√°ticamente si es \n",
    "    gzip (.gz), bzip2 (.bz2) o zip (.zip). El archivo se cierra inmediatamente \n",
    "    al pasar a la siguiente iteraci√≥n, permitiendo procesar archivos muy grandes \n",
    "    sin cargar todo en memoria.\n",
    "    \n",
    "    Args:\n",
    "        filenames (iterable): Secuencia de rutas de archivo (strings)\n",
    "        \n",
    "    Yields:\n",
    "        file object: Objeto de archivo abierto en modo lectura de texto\n",
    "        \n",
    "    Example:\n",
    "        >>> for archivo in gen_opener(['log.txt', 'data.gz', 'archive.zip']):\n",
    "        ...     primera_linea = archivo.readline()\n",
    "        \n",
    "    Note:\n",
    "        Los archivos se cierran autom√°ticamente despu√©s de cada iteraci√≥n.\n",
    "        Para archivos .zip, se lee el primer archivo dentro del ZIP.\n",
    "    \"\"\"\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.gz'):\n",
    "            f = gzip.open(filename, 'rt')\n",
    "        elif filename.endswith('.bz2'):\n",
    "            f = bz2.open(filename, 'rt')\n",
    "        elif filename.endswith('.zip'):\n",
    "            # Para archivos ZIP, abre el primer archivo dentro del ZIP\n",
    "            zf = zipfile.ZipFile(filename, 'r')\n",
    "            first_file = zf.namelist()[0]\n",
    "            f = zf.open(first_file, 'r')\n",
    "        else:\n",
    "            f = open(filename, 'rt')\n",
    "        yield f\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota: Diferencia entre modo `'r'` y `'rt'`\n",
    "\n",
    "La diferencia entre `'r'` y `'rt'` en Python es **muy sutil pero importante**:\n",
    "\n",
    "- **`'r'`**: Abre en modo lectura (por defecto es texto)\n",
    "- **`'rt'`**: Abre expl√≠citamente en modo lectura de **TEXTO** (`'t'` = text mode)\n",
    "\n",
    "### ¬øPor qu√© usamos `'rt'` en este c√≥digo?\n",
    "\n",
    "En `gen_opener()` se usa `'rt'` por **coherencia y claridad**, especialmente porque tambi√©n abrimos archivos comprimidos:\n",
    "\n",
    "```python\n",
    "if filename.endswith('.gz'):\n",
    "    f = gzip.open(filename, 'rt')      # ‚Üê 'rt' expl√≠cito\n",
    "elif filename.endswith('.bz2'):\n",
    "    f = bz2.open(filename, 'rt')       # ‚Üê 'rt' expl√≠cito\n",
    "else:\n",
    "    f = open(filename, 'rt')           # ‚Üê 'rt' expl√≠cito\n",
    "```\n",
    "\n",
    "### Diferencia pr√°ctica en Windows:\n",
    "\n",
    "```python\n",
    "# Modo 'r' (texto con conversi√≥n autom√°tica en Windows)\n",
    "with open('archivo.txt', 'r') as f:\n",
    "    contenido = f.read()\n",
    "    # En Windows: \\r\\n se convierte autom√°ticamente a \\n\n",
    "\n",
    "# Modo 'rt' (equivalente, pero expl√≠cito)\n",
    "with open('archivo.txt', 'rt') as f:\n",
    "    contenido = f.read()\n",
    "    # Mismo comportamiento, pero m√°s claro\n",
    "```\n",
    "\n",
    "### Respuesta: ¬øEs necesario?\n",
    "\n",
    "**No es estrictamente necesario**. `'r'` ser√≠a suficiente. Se usa `'rt'` para:\n",
    "\n",
    "1. ‚úÖ Ser **expl√≠cito** - dejar claro que es modo texto\n",
    "2. ‚úÖ **Coherencia** - mantener uniformidad con `gzip.open()` y `bz2.open()`\n",
    "3. ‚úÖ **Legibilidad** - mejorar la comprensi√≥n del c√≥digo\n",
    "\n",
    "**Conclusi√≥n**: Puedes cambiar `'rt'` por `'r'` sin problema, funcionar√° igual. La `'t'` es solo para ser expl√≠cito y mejorar la legibilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soporte para archivos ZIP\n",
    "\n",
    "La funci√≥n ahora soporta archivos `.zip`. Cuando detecta un archivo ZIP:\n",
    "- Abre el ZIP\n",
    "- Lee el nombre del primer archivo dentro del ZIP\n",
    "- Abre ese primer archivo para lectura\n",
    "\n",
    "**Limitaci√≥n actual:** Solo procesa el primer archivo dentro del ZIP.\n",
    "\n",
    "**¬øQu√© pasa si el ZIP tiene m√∫ltiples archivos?**\n",
    "\n",
    "Si necesitas procesar **todos los archivos** dentro del ZIP, tienes varias opciones:\n",
    "\n",
    "#### **Opci√≥n 1: Iterar sobre todos los archivos del ZIP**\n",
    "```python\n",
    "def gen_opener_all_files(filenames):\n",
    "    \"\"\"Abre archivos, procesando TODOS los archivos dentro de ZIPs\"\"\"\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.zip'):\n",
    "            zf = zipfile.ZipFile(filename, 'r')\n",
    "            for inner_file in zf.namelist():\n",
    "                if not inner_file.endswith('/'):  # Ignorar directorios\n",
    "                    f = zf.open(inner_file, 'r')\n",
    "                    yield f\n",
    "                    f.close()\n",
    "        else:\n",
    "            # ... resto del c√≥digo para .gz, .bz2, etc\n",
    "```\n",
    "\n",
    "#### **Opci√≥n 2: Especificar qu√© archivo leer del ZIP**\n",
    "```python\n",
    "def gen_opener_with_index(filenames, zip_index=0):\n",
    "    \"\"\"Especifica qu√© archivo leer del ZIP (por √≠ndice)\"\"\"\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.zip'):\n",
    "            zf = zipfile.ZipFile(filename, 'r')\n",
    "            files = zf.namelist()\n",
    "            if len(files) > zip_index:\n",
    "                f = zf.open(files[zip_index], 'r')\n",
    "                yield f\n",
    "                f.close()\n",
    "```\n",
    "\n",
    "**Ejemplo de uso:**\n",
    "```python\n",
    "# Opci√≥n 1: Procesar todos los archivos\n",
    "for f in gen_opener_all_files(['datos.zip', 'respaldo.gz']):\n",
    "    print(f.readline())\n",
    "\n",
    "# Opci√≥n 2: Procesar segundo archivo del ZIP\n",
    "for f in gen_opener_with_index(['datos.zip'], zip_index=1):\n",
    "    print(f.readline())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versi√≥n alternativa 1: Procesar TODOS los archivos dentro del ZIP\n",
    "def gen_opener_all_files(filenames):\n",
    "    \"\"\"Abre archivos, procesando TODOS los archivos dentro de ZIPs.\n",
    "    \n",
    "    Si encuentra un ZIP con m√∫ltiples archivos, abre cada uno secuencialmente.\n",
    "    \"\"\"\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.gz'):\n",
    "            f = gzip.open(filename, 'rt')\n",
    "            yield f\n",
    "            f.close()\n",
    "        elif filename.endswith('.bz2'):\n",
    "            f = bz2.open(filename, 'rt')\n",
    "            yield f\n",
    "            f.close()\n",
    "        elif filename.endswith('.zip'):\n",
    "            # Procesa TODOS los archivos dentro del ZIP\n",
    "            zf = zipfile.ZipFile(filename, 'r')\n",
    "            for inner_file in zf.namelist():\n",
    "                if not inner_file.endswith('/'):  # Ignorar directorios\n",
    "                    f = zf.open(inner_file, 'r')\n",
    "                    yield f\n",
    "                    f.close()\n",
    "        else:\n",
    "            f = open(filename, 'rt')\n",
    "            yield f\n",
    "            f.close()\n",
    "\n",
    "\n",
    "# Versi√≥n alternativa 2: Especificar qu√© archivo leer del ZIP\n",
    "def gen_opener_with_index(filenames, zip_index=0):\n",
    "    \"\"\"Abre archivos, permitiendo especificar cu√°l archivo leer del ZIP.\n",
    "    \n",
    "    Args:\n",
    "        filenames: Rutas de archivo\n",
    "        zip_index: √çndice del archivo a leer del ZIP (por defecto 0 = primero)\n",
    "    \"\"\"\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.gz'):\n",
    "            f = gzip.open(filename, 'rt')\n",
    "            yield f\n",
    "            f.close()\n",
    "        elif filename.endswith('.bz2'):\n",
    "            f = bz2.open(filename, 'rt')\n",
    "            yield f\n",
    "            f.close()\n",
    "        elif filename.endswith('.zip'):\n",
    "            zf = zipfile.ZipFile(filename, 'r')\n",
    "            files = [f for f in zf.namelist() if not f.endswith('/')]\n",
    "            if len(files) > zip_index:\n",
    "                f = zf.open(files[zip_index], 'r')\n",
    "                yield f\n",
    "                f.close()\n",
    "        else:\n",
    "            f = open(filename, 'rt')\n",
    "            yield f\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_io.TextIOWrapper name='d:\\\\recetas-python\\\\Capitulo 4 (Iterables y Generadotres)\\\\cap4-1-7.ipynb' mode='rt' encoding='cp1252'>,\n",
       " <_io.TextIOWrapper name='d:\\\\recetas-python\\\\Capitulo 4 (Iterables y Generadotres)\\\\cap4-11-15-walrus-match-case.ipynb' mode='rt' encoding='cp1252'>,\n",
       " <_io.TextIOWrapper name='d:\\\\recetas-python\\\\Capitulo 4 (Iterables y Generadotres)\\\\cap4-8-10.ipynb' mode='rt' encoding='cp1252'>,\n",
       " <_io.TextIOWrapper name='d:\\\\recetas-python\\\\Capitulo 4 (Iterables y Generadotres)\\\\cap4.tar.gz' encoding='cp1252'>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gen_opener(archivos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_concatenate(iterators):\n",
    "    \"\"\"Encadena m√∫ltiples iteradores en una sola secuencia continua.\n",
    "    \n",
    "    Toma una secuencia de iteradores y emite todos sus elementos \n",
    "    consecutivamente, simplificando la iteraci√≥n sobre m√∫ltiples fuentes \n",
    "    de datos sin necesidad de bucles anidados.\n",
    "    \n",
    "    Args:\n",
    "        iterators (iterable): Secuencia de iteradores a concatenar\n",
    "        \n",
    "    Yields:\n",
    "        any: Elementos de todos los iteradores, en orden\n",
    "        \n",
    "    Example:\n",
    "        >>> it1 = iter([1, 2, 3])\n",
    "        >>> it2 = iter([4, 5, 6])\n",
    "        >>> list(gen_concatenate([it1, it2]))\n",
    "        [1, 2, 3, 4, 5, 6]\n",
    "    \"\"\"\n",
    "    for it in iterators:\n",
    "        yield from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_grep(pattern, lines):\n",
    "    \"\"\"Filtra l√≠neas que coinciden con una expresi√≥n regular.\n",
    "    \n",
    "    Busca un patr√≥n de expresi√≥n regular en una secuencia de l√≠neas \n",
    "    y emite solo las que contienen una coincidencia.\n",
    "    \n",
    "    Args:\n",
    "        pattern (str): Expresi√≥n regular a buscar\n",
    "        lines (iterable): Secuencia de l√≠neas de texto\n",
    "        \n",
    "    Yields:\n",
    "        str: L√≠neas que coinciden con el patr√≥n\n",
    "        \n",
    "    Example:\n",
    "        >>> lineas = ['python es genial', 'java tambi√©n', 'python rules']\n",
    "        >>> list(gen_grep('python', lineas))\n",
    "        ['python es genial', 'python rules']\n",
    "    \"\"\"\n",
    "    pat = re.compile(pattern)\n",
    "    for line in lines:\n",
    "        if pat.search(line):\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lognames = gen_find('access-log*', '/home/emi')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('(?i)python', lines)\n",
    "for line in pylines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desea ampliar a√∫n m√°s la canalizaci√≥n, incluso puede alimentar los datos en expresiones generadoras. Por ejemplo, esta versi√≥n encuentra el n√∫mero de bytes transferidos y suma el total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ognames = gen_find('access-log*', '/home/emi')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('(?i)python', lines)\n",
    "bytecolumn = (line.rsplit(None,1)[1] for line in pylines)\n",
    "bytes_ = (int(x) for x in bytecolumn if x != '-')\n",
    "print('Total', sum(bytes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procesamiento de datos de manera canalizada funciona bien para una amplia variedad de otros problemas, incluido el an√°lisis, la lectura de fuentes de datos en tiempo real, el sondeo peri√≥dico, etc. Para comprender el c√≥digo, es importante comprender que la declaraci√≥n de rendimiento act√∫a como una especie de productor de datos, mientras que un bucle for act√∫a como un consumidor de datos. Cuando los generadores se apilan, cada rendimiento alimenta un solo elemento de datos a la siguiente etapa de la tuber√≠a que lo consume con iteraci√≥n. En el √∫ltimo ejemplo, la funci√≥n sum () en realidad est√° impulsando todo el programa, sacando un elemento a la vez de la tuber√≠a de generadores.\n",
    "Una caracter√≠stica interesante de este enfoque es que cada funci√≥n del generador tiende a ser peque√±a y aut√≥noma. Como tales, son f√°ciles de escribir y mantener. En muchos casos, tienen un prop√≥sito tan general que pueden reutilizarse en otros contextos. El c√≥digo resultante que pega\n",
    "los componentes juntos tambi√©n tienden a leerse como una receta simple que se entiende f√°cilmente.  \n",
    "\n",
    "La eficiencia de memoria de este enfoque tampoco puede ser exagerada. El c√≥digo que se muestra funcionar√≠a incluso si se usara en un directorio masivo de archivos. De hecho, debido a la naturaleza iterativa del procesamiento, se utilizar√≠a muy poca memoria.  \n",
    "\n",
    "Hay un poco de extrema sutileza en la funci√≥n gen_concatenate (). El prop√≥sito de esta funci√≥n es concatenar secuencias de entrada juntas en una secuencia larga de l√≠neas. La funci√≥n itertools.chain () realiza una funci√≥n similar, pero requiere que todos los iterables encadenados se especifiquen como argumentos. En el caso de esta receta en particular, hacer eso implicar√≠a una declaraci√≥n como lines = itertools.chain (* files), lo que har√≠a que el generador gen_opener () se consumiera por completo. Dado que ese generador est√° produciendo una secuencia de archivos abiertos que se cierran inmediatamente en el siguiente paso de iteraci√≥n, no se puede usar chain (). La soluci√≥n mostrada evita este problema.  \n",
    "\n",
    "Tambi√©n aparece en la funci√≥n gen_concatenate () el uso de yield from para delegar a un subgenerador. El resultado de la declaraci√≥n de √©l simplemente hace que gen_concatenate () emita todos los valores producidos por el generador.  \n",
    "\n",
    "Por √∫ltimo, pero no menos importante, debe tenerse en cuenta que un enfoque canalizado no siempre funciona para todos los problemas de manejo de datos. A veces, solo necesita trabajar con todos los datos a la vez. Sin embargo, incluso en ese caso, el uso de canalizaciones de generador puede ser una forma de dividir l√≥gicamente un problema en una especie de flujo de trabajo.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplanar una secuencia anidada\n",
    "\n",
    "4.13\n",
    "\n",
    "- Problema\n",
    "        Tiene una secuencia anidada que desea aplanar en una √∫nica lista de valores.\n",
    "\n",
    "\n",
    "- Soluci√≥n\n",
    "        Esto se resuelve f√°cilmente escribiendo una funci√≥n generadora recursiva que implique un rendimiento de declaraci√≥n. \n",
    "        \n",
    "Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(items, ignore_types=(str, bytes)):\n",
    "    for x in items:\n",
    "        if isinstance(x, (list,tuple,set)): \n",
    "            yield from flatten(x)\n",
    "        elif isinstance(x,(int,float,str)):\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1, 2, [ 3, 4, [5, 6], 7 ], 8,{1,2,3},{1:\"uno\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(flatten(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dave\n",
      "Paula\n",
      "Thomas\n",
      "Lewis\n"
     ]
    }
   ],
   "source": [
    "nombres = ['Dave', 'Paula', ['Thomas', 'Lewis']]\n",
    "for x in flatten(nombres):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten2(items, ignore_types=(str, bytes)):\n",
    "    from collections.abc import Iterable\n",
    "    for x in items:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, ignore_types):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(flatten2(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dave', 'Paula', 'Thomas', 'Lewis']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(flatten2(nombres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el c√≥digo, isinstance (x, Iterable) simplemente comprueba si un elemento es iterable.\n",
    "Si es as√≠, yield from se utiliza para emitir todos sus valores como una especie de subrutina. El final resulto\n",
    "es una √∫nica secuencia de salida sin anidamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La declaraci√≥n `yield from ` es un buen atajo para usar si alguna vez desea escribir generadores\n",
    "que llaman a otros generadores como subrutinas. Si no lo usa, debe escribir un c√≥digo que\n",
    "utiliza un bucle for adicional. Por ejemplo:\n",
    "\n",
    "```python\n",
    "        def flatten(items, ignore_types=(str, bytes)):\n",
    "            for x in items:\n",
    "                if isinstance(x, Iterable) and \n",
    "                   not isinstance(x, ignore_types):\n",
    "                    for i in flatten(x):\n",
    "                        yield i\n",
    "                else:\n",
    "                    yield x\n",
    "```\n",
    "\n",
    "Aunque es solo un cambio menor, el rendimiento de la declaraci√≥n simplemente se siente mejor y conduce a un c√≥digo m√°s limpio. Como se se√±al√≥, la verificaci√≥n adicional de cadenas y bytes est√° ah√≠ para evitar la expansi√≥n de esos tipos en caracteres individuales. Si hay otros tipos que no desea expandir, puede proporcionar un valor diferente para el argumento ignore_types. Finalmente, debe tenerse en cuenta que `yield` tiene un papel m√°s importante en los programas avanzados que involucran corrutinas y concurrencia basada en generadores. Vea la receta 12.12 para\n",
    "otro ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterando en orden clasificado sobre combinado clasificado Iterables\n",
    "\n",
    "4.15\n",
    "\n",
    "- Problema\n",
    "        Tiene una colecci√≥n de secuencias ordenadas y desea iterar sobre una secuencia ordenada de todos ellos se fusionaron.  \n",
    "        \n",
    "        \n",
    "\n",
    "- Soluci√≥n\n",
    "        La funci√≥n heapq.merge () hace exactamente lo que quieres.  \n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 4, 7, 10]\n",
    "b = [2, 5, 6, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 7, 10, 2, 5, 6, 11]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for c in heapq.merge(a, b):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 6, 7, 10, 11]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(heapq.merge(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La naturaleza iterativa de heapq.merge significa que nunca lee ninguna de los secuencias proporcionadas a la vez. Esto significa que puede usarlo en secuencias muy largas con muy poca sobrecarga.   \n",
    "Por ejemplo, aqu√≠ hay un ejemplo de c√≥mo fusionar√≠a dos archivos:\n",
    "\n",
    "import heapq\n",
    "with open('archivo_1', 'rt') as file1, \\\n",
    "     open('archivo_2') 'rt' as file2, \\\n",
    "     open('archivo_final', 'wt') as outf:\n",
    "    for line in heapq.merge(file1, file2):\n",
    "        outf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "with open('archivo1', 'r') as file1, open('archivo2','r') as file2, \\\n",
    "     open('archivo_final', 'w') as outf:\n",
    "    for line in heapq.merge(file1, file2):\n",
    "        outf.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante enfatizar que heapq.merge () requiere que todas las secuencias de entrada ya est√©n ordenadas. En particular, no lee primero todos los datos en un mont√≥n ni realiza ninguna clasificaci√≥n preliminar. Tampoco realiza ning√∫n tipo de validaci√≥n de las entradas a comprobar\n",
    "si cumplen con los requisitos de pedido. En su lugar, simplemente examina el conjunto de elementos del frente de cada secuencia de entrada y emite el m√°s peque√±o encontrado. Luego se lee un nuevo elemento de la secuencia elegida y el proceso se repite hasta que todas las secuencias de entrada\n",
    "se han consumido por completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîÑ Modernizaci√≥n para Python 3.8+ \n",
    "\n",
    "Esta secci√≥n muestra c√≥mo modernizar el c√≥digo anterior aprovechando las caracter√≠sticas de Python 3.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Usar Pathlib en lugar de os.path (Python 3.4+)\n",
    "\n",
    "**Versi√≥n antigua** (usando `os.path`):\n",
    "```python\n",
    "def gen_find(busqueda, top):\n",
    "    for path, carpetas, archivos in os.walk(top):\n",
    "        for nombre in fnmatch.filter(archivos, busqueda):\n",
    "            yield os.path.join(path, nombre)\n",
    "```\n",
    "\n",
    "**Versi√≥n moderna** (usando `pathlib.Path`):\n",
    "- ‚úÖ M√°s legible y orientado a objetos\n",
    "- ‚úÖ Multiplataforma autom√°tico (Windows/Linux/Mac)\n",
    "- ‚úÖ M√©todos integrados como `.glob()`, `.match()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def gen_find_modern(pattern: str, top: str | Path):\n",
    "    \"\"\"\n",
    "    Versi√≥n moderna usando pathlib.\n",
    "    Encuentra todos los archivos que coinciden con el patr√≥n.\n",
    "    \"\"\"\n",
    "    top_path = Path(top) if isinstance(top, str) else top\n",
    "    \n",
    "    # glob() es m√°s simple y directo que os.walk + fnmatch\n",
    "    yield from top_path.rglob(pattern)  # rglob = recursive glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "archivos_modernos = list(gen_find_modern(\"cap4*.*\", Path.cwd()))\n",
    "print(f\"Encontrados {len(archivos_modernos)} archivos:\")\n",
    "for archivo in archivos_modernos[:3]:  # Mostrar solo los primeros 3\n",
    "    print(f\"  - {archivo.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Operador Walrus `:=` para simplificar c√≥digo (Python 3.8+)\n",
    "\n",
    "**Versi√≥n antigua**:\n",
    "```python\n",
    "def gen_opener(filenames):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.gz'):\n",
    "            f = gzip.open(filename, 'rt')\n",
    "        elif filename.endswith('.bz2'):\n",
    "            f = bz2.open(filename, 'rt')\n",
    "        else:\n",
    "            f = open(filename, 'rt')\n",
    "        yield f\n",
    "        f.close()\n",
    "```\n",
    "\n",
    "**Versi√≥n moderna con walrus**:\n",
    "- ‚úÖ Reduce repetici√≥n de c√≥digo\n",
    "- ‚úÖ M√°s conciso y expresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def open_file_smart(filepath: Path):\n",
    "    \"\"\"Context manager que abre archivos seg√∫n su extensi√≥n.\"\"\"\n",
    "    if filepath.suffix == '.gz':\n",
    "        f = gzip.open(filepath, 'rt')\n",
    "    elif filepath.suffix == '.bz2':\n",
    "        f = bz2.open(filepath, 'rt')\n",
    "    else:\n",
    "        f = open(filepath, 'rt')\n",
    "    try:\n",
    "        yield f\n",
    "    finally:\n",
    "        f.close()\n",
    "\n",
    "def gen_opener_modern(filenames):\n",
    "    \"\"\"Versi√≥n moderna usando pathlib y context managers.\"\"\"\n",
    "    for filename in filenames:\n",
    "        path = Path(filename) if isinstance(filename, str) else filename\n",
    "        with open_file_smart(path) as f:\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Pattern Matching con match-case (Python 3.10+)\n",
    "\n",
    "**Versi√≥n antigua** (flatten con if-elif):\n",
    "```python\n",
    "def flatten(items, ignore_types=(str, bytes)):\n",
    "    for x in items:\n",
    "        if isinstance(x, (list,tuple,set)): \n",
    "            yield from flatten(x)\n",
    "        elif isinstance(x,(int,float,str)):\n",
    "            yield x\n",
    "```\n",
    "\n",
    "**Versi√≥n moderna con match-case**:\n",
    "- ‚úÖ M√°s expresivo y legible\n",
    "- ‚úÖ Pattern matching estructural\n",
    "- ‚úÖ Detecci√≥n de tipos m√°s elegante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "def flatten_modern(items, ignore_types=(str, bytes)):\n",
    "    \"\"\"\n",
    "    Versi√≥n moderna usando match-case (Python 3.10+)\n",
    "    Aplana una secuencia anidada recursivamente.\n",
    "    \"\"\"\n",
    "    for x in items:\n",
    "        match x:\n",
    "            # Si es iterable pero NO string/bytes\n",
    "            case _ if isinstance(x, Iterable) and not isinstance(x, ignore_types):\n",
    "                yield from flatten_modern(x, ignore_types)\n",
    "            # Cualquier otro tipo (n√∫meros, strings, etc.)\n",
    "            case _:\n",
    "                yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba comparativa\n",
    "items_test = [1, 2, [3, 4, [5, 6], 7], 8, {9, 10, 11}, 'texto']\n",
    "\n",
    "print(\"Versi√≥n antigua:\")\n",
    "print(list(flatten(items_test)))\n",
    "\n",
    "print(\"\\nVersi√≥n moderna (match-case):\")\n",
    "print(list(flatten_modern(items_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Type Hints Modernos (Python 3.9+)\n",
    "\n",
    "**Cambios principales**:\n",
    "- ‚úÖ `list[int]` en lugar de `List[int]` (no necesita import de typing)\n",
    "- ‚úÖ `dict[str, int]` en lugar de `Dict[str, int]`\n",
    "- ‚úÖ `tuple[int, ...]` en lugar de `Tuple[int, ...]`\n",
    "- ‚úÖ `str | int` en lugar de `Union[str, int]` (Python 3.10+)\n",
    "- ‚úÖ `X | None` en lugar de `Optional[X]` (Python 3.10+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator, Iterable\n",
    "from pathlib import Path\n",
    "\n",
    "# Versi√≥n con type hints modernos (Python 3.10+)\n",
    "def gen_grep_modern(\n",
    "    pattern: str, \n",
    "    lines: Iterable[str]\n",
    ") -> Iterator[str]:\n",
    "    \"\"\"\n",
    "    Busca un patr√≥n regex en l√≠neas.\n",
    "    \n",
    "    Args:\n",
    "        pattern: Expresi√≥n regular a buscar\n",
    "        lines: Secuencia de l√≠neas de texto\n",
    "        \n",
    "    Yields:\n",
    "        L√≠neas que coinciden con el patr√≥n\n",
    "    \"\"\"\n",
    "    pat = re.compile(pattern)\n",
    "    for line in lines:\n",
    "        if pat.search(line):\n",
    "            yield line\n",
    "\n",
    "def gen_find_typed(\n",
    "    pattern: str, \n",
    "    top: str | Path\n",
    ") -> Iterator[Path]:\n",
    "    \"\"\"\n",
    "    Encuentra archivos que coinciden con el patr√≥n.\n",
    "    \n",
    "    Args:\n",
    "        pattern: Patr√≥n glob (ej: '*.txt')\n",
    "        top: Directorio ra√≠z (string o Path)\n",
    "        \n",
    "    Yields:\n",
    "        Rutas de archivos encontrados\n",
    "    \"\"\"\n",
    "    top_path = Path(top) if isinstance(top, str) else top\n",
    "    yield from top_path.rglob(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Pipeline de procesamiento completo modernizado\n",
    "\n",
    "Juntando todas las mejoras anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline completo modernizado (Python 3.10+)\n",
    "from pathlib import Path\n",
    "from collections.abc import Iterator\n",
    "import re\n",
    "\n",
    "# 1. Buscar archivos .ipynb en el directorio actual\n",
    "notebooks = gen_find_typed(\"*.ipynb\", Path.cwd())\n",
    "\n",
    "# 2. Abrir archivos (simplificado - notebooks son texto plano)\n",
    "def read_notebooks(paths: Iterator[Path]) -> Iterator[str]:\n",
    "    \"\"\"Lee l√≠neas de m√∫ltiples archivos.\"\"\"\n",
    "    for path in paths:\n",
    "        with path.open('r', encoding='utf-8') as f:\n",
    "            yield from f\n",
    "\n",
    "# 3. Filtrar l√≠neas que contienen 'python'\n",
    "lines = read_notebooks(notebooks)\n",
    "python_lines = gen_grep_modern(r'(?i)python', lines)\n",
    "\n",
    "# 4. Contar ocurrencias\n",
    "print(\"L√≠neas con 'python' en notebooks:\")\n",
    "count = 0\n",
    "for line in python_lines:\n",
    "    if (count := count + 1) <= 5:  # Walrus operator! \n",
    "        print(f\"{count}: {line.strip()[:60]}...\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"\\n‚úÖ Pipeline ejecutado con √©xito (Python 3.10+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Resumen de Modernizaciones\n",
    "\n",
    "| Caracter√≠stica | Python < 3.8 | Python 3.8+ | Python 3.10+ |\n",
    "|---------------|--------------|-------------|---------------|\n",
    "| **Paths** | `os.path.join()` | `pathlib.Path` | `pathlib.Path` |\n",
    "| **Type hints** | `List[int]` | `list[int]` | `str \\| int` |\n",
    "| **Asignaci√≥n** | `x = expr; if x:` | `if (x := expr):` | `if (x := expr):` |\n",
    "| **Pattern matching** | `if/elif/else` | `if/elif/else` | `match/case` |\n",
    "| **Union types** | `Union[str, int]` | `Union[str, int]` | `str \\| int` |\n",
    "| **Optional** | `Optional[str]` | `Optional[str]` | `str \\| None` |\n",
    "\n",
    "### Beneficios de modernizar:\n",
    "\n",
    "‚úÖ **C√≥digo m√°s conciso** - Menos boilerplate  \n",
    "‚úÖ **Mejor legibilidad** - Patrones m√°s claros  \n",
    "‚úÖ **Type safety** - Mejor detecci√≥n de errores con mypy/pylance  \n",
    "‚úÖ **Performance** - Algunas optimizaciones internas  \n",
    "‚úÖ **Mantenibilidad** - Aprovecha idiomas modernos de Python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno",
   "language": "python",
   "name": "entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
