{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambio de formato de texto a un número fijo de columnas\n",
    "2.16\n",
    "\n",
    "- Problema\n",
    "        \n",
    "        Tiene cadenas largas que desea reformatear para que llenen un número especificado por el usuario de columnas.  \n",
    "\n",
    "\n",
    "- Solución\n",
    "        \n",
    "        Utilice el módulo de envoltura de texto para reformatear el texto para la salida. Por ejemplo, suponga que tiene la siguiente cadena larga:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, le mostramos cómo puede usar el módulo de envoltura de texto para reformatearlo de varias maneras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TextWrapper', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_leading_whitespace_re', '_whitespace', '_whitespace_only_re', 'dedent', 'fill', 'indent', 're', 'shorten', 'wrap']\n"
     ]
    }
   ],
   "source": [
    "print(dir(textwrap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,\n",
      "not around the eyes, don't look around the eyes, look into my eyes,\n",
      "you're under.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(s, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes,\n",
      "the eyes, the eyes, the eyes, not around\n",
      "the eyes, don't look around the eyes,\n",
      "look into my eyes, you're under.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(s, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Look into my eyes, look into my\n",
      "eyes, the eyes, the eyes, the eyes, not\n",
      "around the eyes, don't look around the\n",
      "eyes, look into my eyes, you're under.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(s, 40, initial_indent=\"     \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes,\n",
      "    |the eyes, the eyes, the eyes, not\n",
      "    |around the eyes, don't look around\n",
      "    |the eyes, look into my eyes, you're\n",
      "    |under.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(s, 40, subsequent_indent=\"    |\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Look into my eyes, look',\n",
       " 'into my eyes, the eyes,',\n",
       " 'the eyes, the eyes, not',\n",
       " \"around the eyes, don't\",\n",
       " 'look around the eyes,',\n",
       " \"look into my eyes, you're\",\n",
       " 'under.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textwrap.wrap(s,width=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"afdsafsafsakfhsajkgbakghfsakfgs asdfdajhfgjagsdf asfhajhf asdfksfg rgtreoteg bddsh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afdsafsafs',\n",
       " 'akfhsajkgb',\n",
       " 'akghfsakfg',\n",
       " 's asdfdajh',\n",
       " 'fgjagsdf',\n",
       " 'asfhajhf',\n",
       " 'asdfksfg',\n",
       " 'rgtreoteg',\n",
       " 'bddsh']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textwrap.wrap(text,width=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "El modulo textwrap es una forma sencilla de limpiar el texto para imprimirlo, especialmente si desea que la salida se ajuste bien en la terminal. En cuanto al tamaño de la terminal, puede obtenerlo usando os.get_terminal_size(). \n",
    "\n",
    "Por ejemplo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 25] Inappropriate ioctl for device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_terminal_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 25] Inappropriate ioctl for device"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.get_terminal_size().columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error OSError: [Errno 25] Inappropriate ioctl for device.  \n",
    "\n",
    "Ocurre porque `os.get_terminal_size()` está siendo llamado en un entorno donde no hay un terminal asociado, como en un Jupyter Notebook.\n",
    "\n",
    "Para evitar este error, puedes usar una comprobación para asegurarte de que el código solo se ejecute si hay un terminal disponible. Aquí tienes una forma de hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 25] Inappropriate ioctl for device\n",
      "Ancho del terminal: 80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def get_terminal_width():\n",
    "    try:\n",
    "        return os.get_terminal_size().columns\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        # Fallback to a default value or use shutil.get_terminal_size()\n",
    "        # Si la fallback falla, usar shutil.get_terminal_size()\n",
    "        return shutil.get_terminal_size().columns\n",
    "\n",
    "terminal_width = get_terminal_width()\n",
    "print(f\"Ancho del terminal: {terminal_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de entidades HTML y XML en texto\n",
    "\n",
    "2.17\n",
    "\n",
    "- Problema\n",
    "        \n",
    "        Desea reemplazar entidades HTML o XML como & entity; o & # code; con su texto correspondiente. Alternativamente, necesita producir texto, pero escapar de ciertos caracteres (por ejemplo, <,> o &).\n",
    "\n",
    "\n",
    "- Solución\n",
    "\n",
    "        Si está produciendo texto, reemplazar caracteres especiales como <o> es relativamente fácil si utiliza la función html.escape().   \n",
    "        \n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elements are written as \"<tag>text</tag>\".'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Elements are written as \"<tag>text</tag>\".'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\n"
     ]
    }
   ],
   "source": [
    "print(html.escape(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are written as \"&lt;tag&gt;text&lt;/tag&gt;\".\n"
     ]
    }
   ],
   "source": [
    "print(html.escape(s, quote=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'The prompt is &gt;&gt;&gt;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prompt is >>>'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.unescape(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy \"Jalapeño\".'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Spicy &quot;Jalape&#241;o&quot.'\n",
    "html.unescape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('child1', 'data1'), ('child2', 'data2'), ('child3', 'data3')]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_data = '''<root>\n",
    "    <child1>data1</child1>\n",
    "    <child2>data2</child2>\n",
    "    <child3>data3</child3>\n",
    "</root>'''\n",
    "\n",
    "# Parse the XML data\n",
    "root = ET.fromstring(xml_data)\n",
    "\n",
    "# Function to tokenize XML\n",
    "def tokenize_xml(element):\n",
    "    tokens = []\n",
    "    for child in element:\n",
    "        tokens.append((child.tag, child.text))\n",
    "        tokens.extend(tokenize_xml(child))\n",
    "    return tokens\n",
    "\n",
    "# Tokenize the XML data\n",
    "tokens = tokenize_xml(root)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización de texto\n",
    "\n",
    "2.18\n",
    "\n",
    "- Problema\n",
    "        \n",
    "        Tiene una cadena que desea analizar de izquierda a derecha en una secuencia de tokens.  \n",
    "\n",
    "\n",
    "- Solución\n",
    "        \n",
    "        Suponga que tiene una cadena de texto como esta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'foo=23+42*10.5/4%2 // 34**2-3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tokenizar la cadena, necesita hacer más que simplemente hacer coincidir patrones.  \n",
    "Tambien necesitas alguna forma de identificar el tipo de patrón.   \n",
    "\n",
    "Por ejemplo, es posible que desee convierte la cadena en una secuencia de pares como esta:\n",
    "\n",
    "```python\n",
    "tokens = [('Variable', 'foo'), ('igual','='), ('numero', '23'), ('suma','+'),('numero', '42'), ('multipacion', '*'), ('numero', 10')]\n",
    "```\n",
    "Para hacer este tipo de división, el primer paso es definir todos los tokens posibles, incluidos espacios en blanco, mediante patrones de expresión regular utilizando grupos de captura con nombre como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p1 = r'(?P<Variable>[a-zA-Z_][a-zA-Z_0-9]*)' \n",
    "p2 = r'(?P<igual>=)'\n",
    "p3 = r'(?P<suma>\\+)'\n",
    "p4 = r'(?P<mulpiplicacion>\\*)'\n",
    "p5 = r'(?P<resta>-)'\n",
    "p6 = r'(?P<divicion>\\/)\\s'\n",
    "p7 = r'(?P<modulo>%)'\n",
    "p8 = r'(?P<divicion_exacta>\\//)'\n",
    "p9 = r'(?P<float>(\\d+[.]\\d+))\\s*'\n",
    "p0 = r'(?P<int>(\\d+\\s*$|\\d+\\s*))'\n",
    "p  = r'(?P<espacio>\\s+)'\n",
    "pp = r'(?P<potencia>\\*\\*)'\n",
    "LT = r'(?P<Menor><)'\n",
    "LE = r'(?P<Menor_Igual><=)'\n",
    "GT = r'(?P<Mayor>>)'\n",
    "GE = r'(?P<Mayor_Igual>>=)'\n",
    "LP = r'(?P<Parentecis_izq>\\()'\n",
    "RP = r'(?P<Parentecis_der>\\))'\n",
    "master_pat = re.compile('|'.join([LE,GE,LT,GT,pp,p1,p2,p3,p4,p5,p6,p7,p8,p9,p0,p,LP,RP]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner = master_pat.scanner('foo = 42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=scanner.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Menor_Igual': None,\n",
       " 'Mayor_Igual': None,\n",
       " 'Menor': None,\n",
       " 'Mayor': None,\n",
       " 'potencia': None,\n",
       " 'Variable': 'foo',\n",
       " 'igual': None,\n",
       " 'suma': None,\n",
       " 'mulpiplicacion': None,\n",
       " 'resta': None,\n",
       " 'divicion': None,\n",
       " 'modulo': None,\n",
       " 'divicion_exacta': None,\n",
       " 'float': None,\n",
       " 'int': None,\n",
       " 'espacio': None,\n",
       " 'Parentecis_izq': None,\n",
       " 'Parentecis_der': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus=master_pat.scanner(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Variable', 'foo'),\n",
       " ('espacio', ''),\n",
       " ('igual', '='),\n",
       " ('espacio', ''),\n",
       " ('int', '23'),\n",
       " ('suma', '+'),\n",
       " ('int', '42'),\n",
       " ('mulpiplicacion', '*'),\n",
       " ('float', '10.5'),\n",
       " ('int', '4'),\n",
       " ('modulo', '%'),\n",
       " ('int', '2'),\n",
       " ('divicion_exacta', '//'),\n",
       " ('espacio', ''),\n",
       " ('int', '34'),\n",
       " ('potencia', '**'),\n",
       " ('int', '2'),\n",
       " ('resta', '-'),\n",
       " ('int', '3'),\n",
       " ('Mayor', '>'),\n",
       " ('espacio', ''),\n",
       " ('int', '7'),\n",
       " ('Menor', '<'),\n",
       " ('espacio', ''),\n",
       " ('int', '76'),\n",
       " ('Mayor_Igual', '>='),\n",
       " ('int', '13'),\n",
       " ('Menor_Igual', '<='),\n",
       " ('int', '14'),\n",
       " ('Parentecis_izq', '('),\n",
       " ('Variable', 'hola'),\n",
       " ('Parentecis_der', ')'),\n",
       " ('Parentecis_izq', '('),\n",
       " ('float', '12.90'),\n",
       " ('mulpiplicacion', '*'),\n",
       " ('int', '2'),\n",
       " ('Parentecis_der', ')')]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i.lastgroup,i.group().strip()) for i in iter(bus.search,None)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tomar esta técnica y ponerla en código, se puede limpiar y empaquetar fácilmente\n",
    "en un generador como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Token = namedtuple('Token', ['type','value'])\n",
    "\n",
    "def generate_tokens(pat, text):\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.search, None):\n",
    "        yield Token(m.lastgroup, m.group().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='Variable', value='foo')\n",
      "Token(type='espacio', value='')\n",
      "Token(type='igual', value='=')\n",
      "Token(type='espacio', value='')\n",
      "Token(type='int', value='23')\n",
      "Token(type='suma', value='+')\n",
      "Token(type='int', value='42')\n",
      "Token(type='mulpiplicacion', value='*')\n",
      "Token(type='float', value='10.5')\n",
      "Token(type='int', value='4')\n",
      "Token(type='modulo', value='%')\n",
      "Token(type='int', value='2')\n",
      "Token(type='divicion_exacta', value='//')\n",
      "Token(type='espacio', value='')\n",
      "Token(type='int', value='34')\n",
      "Token(type='potencia', value='**')\n",
      "Token(type='int', value='2')\n",
      "Token(type='resta', value='-')\n",
      "Token(type='int', value='3')\n",
      "Token(type='Mayor', value='>')\n",
      "Token(type='espacio', value='')\n",
      "Token(type='int', value='7')\n",
      "Token(type='Menor', value='<')\n",
      "Token(type='espacio', value='')\n",
      "Token(type='int', value='76')\n",
      "Token(type='Mayor_Igual', value='>=')\n",
      "Token(type='int', value='13')\n",
      "Token(type='Menor_Igual', value='<=')\n",
      "Token(type='int', value='14')\n",
      "Token(type='Parentecis_izq', value='(')\n",
      "Token(type='Variable', value='hola')\n",
      "Token(type='Parentecis_der', value=')')\n",
      "Token(type='Parentecis_izq', value='(')\n",
      "Token(type='float', value='12.90')\n",
      "Token(type='mulpiplicacion', value='*')\n",
      "Token(type='int', value='2')\n",
      "Token(type='Parentecis_der', value=')')\n"
     ]
    }
   ],
   "source": [
    "text = 'foo = 23+42*10.5/4%2 // 34**2-3 > 7 < 76 >=13<=14 (hola)(12.90*2)' \n",
    "\n",
    "for tok in generate_tokens(master_pat, text):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desea filtrar el flujo de tokens de alguna manera, puede definir más generador\n",
    "funciones o use una expresión generadora. Por ejemplo, así es como puede filtrar\n",
    "todos los tokens de espacios en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = (tok for tok in generate_tokens(master_pat, text) if tok.type != 'espacio')\n",
    "#for tok in tokens:\n",
    "#    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(type='Variable', value='foo'),\n",
       " Token(type='igual', value='='),\n",
       " Token(type='int', value='23'),\n",
       " Token(type='suma', value='+'),\n",
       " Token(type='int', value='42'),\n",
       " Token(type='mulpiplicacion', value='*'),\n",
       " Token(type='float', value='10.5'),\n",
       " Token(type='int', value='4'),\n",
       " Token(type='modulo', value='%'),\n",
       " Token(type='int', value='2'),\n",
       " Token(type='divicion_exacta', value='//'),\n",
       " Token(type='int', value='34'),\n",
       " Token(type='potencia', value='**'),\n",
       " Token(type='int', value='2'),\n",
       " Token(type='resta', value='-'),\n",
       " Token(type='int', value='3'),\n",
       " Token(type='Mayor', value='>'),\n",
       " Token(type='int', value='7'),\n",
       " Token(type='Menor', value='<'),\n",
       " Token(type='int', value='76'),\n",
       " Token(type='Mayor_Igual', value='>='),\n",
       " Token(type='int', value='13'),\n",
       " Token(type='Menor_Igual', value='<='),\n",
       " Token(type='int', value='14'),\n",
       " Token(type='Parentecis_izq', value='('),\n",
       " Token(type='Variable', value='hola'),\n",
       " Token(type='Parentecis_der', value=')'),\n",
       " Token(type='Parentecis_izq', value='('),\n",
       " Token(type='float', value='12.90'),\n",
       " Token(type='mulpiplicacion', value='*'),\n",
       " Token(type='int', value='2'),\n",
       " Token(type='Parentecis_der', value=')')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tokenización es a menudo el primer paso para tipos más avanzados de análisis y manejo de texto.  \n",
    "Para utilizar la técnica de escaneo que se muestra, hay algunos detalles importantes a tener en cuenta.  \n",
    "Primero, debe asegurarse de identificar todas las secuencias de texto posibles que aparecen en la entrada con un patrón de respuesta correspondiente. Si se encuentra algún texto que no coincida, el escaneo simplemente se detiene. Es por eso que fue necesario especificar el token de espacios en blanco (WS) en el ejemplo.  \n",
    "\n",
    "El orden de los tokens en la expresión regular maestra también es importante. Cuando coincida, vuelva intenta hacer coincidir los patrones en el orden especificado. Por lo tanto, si un patrón es una subcadena de un patrón más largo, debe asegurarse de que el patrón más largo vaya primero. Por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a Simple Recursive Descent Parser\n",
    "# Escribir un analizador de descenso recursivo simple\n",
    "\n",
    "- Problema\n",
    "        \n",
    "        You need to parse text according to a set of grammar rules and perform actions or build an abstract syntax tree representing the input. The grammar is small, so you’d prefer to just write the parser yourself as opposed to using some kind of framework.\n",
    "\n",
    "        Necesita analizar el texto de acuerdo con un conjunto de reglas de gramática y realizar acciones o construir un árbol de sintaxis abstracta que represente la entrada. La gramática es pequeña, por lo que preferiría escribir el analizador usted mismo en lugar de usar algún tipo de marco.\n",
    "\n",
    "- Solución:\n",
    "\n",
    "        En este problema, nos centramos en el problema de analizar texto de acuerdo con una gramática particular. Para hacer esto, probablemente debería comenzar teniendo una especificación formal de la gramática en forma de BNF o EBNF. Por ejemplo, una gramática para expresiones aritméticas simples podría verse así:\n",
    "\n",
    "\n",
    "```text\n",
    "        xpr    ::= expr + term\n",
    "               |\n",
    "               expr - term\n",
    "               |\n",
    "               term\n",
    "        term   ::= term * factor\n",
    "               |\n",
    "                term / factor\n",
    "               |\n",
    "                factor\n",
    "        factor ::= ( expr )\n",
    "               | \n",
    "                NUM\n",
    "```\n",
    "\n",
    "O, altetnativamente, en forma de EBNF:\n",
    "\n",
    "```text\n",
    "        expr ::= term { (+|-) term }*\n",
    "        term ::= factor { (*|/) factor }*\n",
    "        factor ::= ( expr )\n",
    "                | NUM\n",
    "```\n",
    "  \n",
    "\n",
    "En `EBNF`, las partes de una regla encerradas en `{ ... }*` son opcionales. El `*` significa cero o más repeticiones (el mismo significado que en una expresión regular).  \n",
    "\n",
    "Ahora, si no está familiarizado con los mecanismos de trabajo con un BNF, piense en él como una especificación de reglas de sustitución o reemplazo donde los símbolos en el lado izquierdo pueden ser reemplazados por los símbolos en el lado derecho (o viceversa).   \n",
    "\n",
    "Generalmente, lo que sucede durante el análisis es que intenta hacer coincidir el texto de entrada con la gramática haciendo varias sustituciones y expansiones utilizando el BNF.   \n",
    "\n",
    "Para ilustrar, suponga que está analizando una expresión como `3 + 4 * 5` . Esta expresión primero debería descomponerse en una secuencia de tokens, utilizando las técnicas descritas en la Receta 2.18.\n",
    "El resultado podría ser una secuencia de tokens como esta:\n",
    "\n",
    "```text\n",
    "NUM + NUM * NUM\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A partir de ahí, el análisis implica intentar hacer coincidir la gramática con los tokens de entrada haciendo sustituciones:  \n",
    "\n",
    "```text\n",
    "expr\n",
    "expr ::= term { (+|-) term }*\n",
    "expr ::= factor { (*|/) factor }* { (+|-) term }*\n",
    "expr ::= NUM { (*|/) factor }* { (+|-) term }*\n",
    "expr ::= NUM { (+|-) term }*\n",
    "expr ::= NUM + term { (+|-) term }*\n",
    "expr ::= NUM + factor { (*|/) factor }* { (+|-) term }*\n",
    "expr ::= NUM + NUM { (*|/) factor}* { (+|-) term }*\n",
    "expr ::= NUM + NUM * factor { (*|/) factor }* { (+|-) term }*\n",
    "expr ::= NUM + NUM * NUM { (*|/) factor }* { (+|-) term }*\n",
    "expr ::= NUM + NUM * NUM { (+|-) term }*\n",
    "expr ::= NUM + NUM * NUM\n",
    "```\n",
    "\n",
    "Siguientes todos los pasos de sustitución requiere un poco de café, pero están impulsados por mirar la entrada e intentar hacer coincidirla con las reglas de gramática. El primer token de entrada es un NUM, por lo que las sustituciones se centran primero en hacer coincidir esa parte. Una vez que se ha hecho coincidir, la atención se traslada al siguiente token de + y así sucesivamente.   \n",
    "Ciertas partes del lado derecho (por ejemplo, `{ (*/) factor }*)` desaparecen cuando se determina que no pueden hacer coincidir el siguiente token. En un análisis exitoso, todo el lado derecho se expande completamente para hacer coincidir la secuencia de tokens de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con todo el trasfondo anterior en su lugar, aquí hay una receta simple que muestra cómo construir un evaluador de expresiones de descenso recursivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "NUM    = r'(?P<NUM>\\d+)'\n",
    "PLUS   = r'(?P<PLUS>\\+)'\n",
    "MINUS  = r'(?P<MINUS>-)'\n",
    "TIMES  = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS     = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,\n",
    "DIVIDE, LPAREN, RPAREN, WS]))\n",
    "\n",
    "# Tokenizer\n",
    "Token = collections.namedtuple('Token', ['type','value'])\n",
    "\n",
    "def generate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgroup, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser\n",
    "class ExpressionEvaluator:\n",
    "    '''\n",
    "    Implentacion de un parser descendente recursivo.\n",
    "\n",
    "    Cada metodo\n",
    "        implementa una sola regla de la gramática. Use el método ._accept()\n",
    "        para comprobar y aceptar el token de lookahead actual. Use el método\n",
    "        ._expect() para exactamente coincidir y descartar el siguiente token\n",
    "    '''\n",
    "    def parse(self,text):\n",
    "        self.tokens = generate_tokens(text)\n",
    "        self.tok = None\n",
    "        # Last symbol consumed (ultimo simbolo consumido)\n",
    "        self.nexttok = None\n",
    "        # Next symbol tokenized (proximo token)\n",
    "        self._advance()\n",
    "        # Load first lookahead token ()\n",
    "        return self.expr()\n",
    "    \n",
    "    def _advance(self):\n",
    "        'Advance one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
    "\n",
    "    def _accept(self,toktype):\n",
    "        'Test and consume the next token if it matches toktype'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def _expect(self,toktype):\n",
    "        'Consume next token if it matches toktype or raise SyntaxError'\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected ' + toktype)\n",
    "    \n",
    "    # Grammar rules follow\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }*\"\n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "\n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }*\"\n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "\n",
    "    def factor(self):\n",
    "        \"factor ::= NUM | ( expr )\"\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ExpressionEvaluator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + 3 * 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + (3 + 4) * 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'SyntaxError'> Expected NUMBER or LPAREN\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    e.parse('2 + (3 + * 4)')\n",
    "except Exception as error:\n",
    "    print(type(error), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + (3 + 4 * 5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realización de operaciones de texto en cadenas de bytes\n",
    "\n",
    "2.20\n",
    "\n",
    "- Problema\n",
    "\n",
    "        Desea realizar operaciones de texto comunes (por ejemplo, eliminar, buscar y reemplazar en cadenas de bytes.  \n",
    "        \n",
    "- Solución\n",
    "\n",
    "        Las cadenas de bytes ya admiten la mayoría de las mismas operaciones integradas que las cadenas de texto.   \n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = b'Hello World'\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.startswith(b'Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Hello', b'World']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello Cruel World'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace(b'Hello', b'Hello Cruel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'Hello')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bytearray(b'Hello World')\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.startswith(b'Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bytearray(b'Hello'), bytearray(b'World')]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'Hello Cruel World')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace(b'Hello', b'Hello Cruel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFOO:BAR,SPAM\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[:,]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/re.py:230\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(pattern, string, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124;03m\"\"\"Split the source string by the occurrences of the pattern,\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    returning a list containing the resulting substrings.  If\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    capturing parentheses are used in pattern, then the text of all\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    and the remainder of the string is returned as the final element\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    of the list.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxsplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "data = b'FOO:BAR,SPAM'\n",
    "\n",
    "import re\n",
    "\n",
    "re.split('[:,]',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'FOO', b'BAR', b'SPAM']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = b'FOO:BAR,SPAM'\n",
    "import re\n",
    "re.split(b'[:,]',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H', 72)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Hello World'\n",
    "b = b'Hello World'\n",
    "a[0],b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
